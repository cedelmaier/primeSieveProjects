These benchmarks are meaningless, as between computers with multicore
capabilities, different speeds and instructions sets, compilers, and on
it really doesn't matter.  So here's mine.

OSX Yosemite
2.66 GHz Intel Core 2 Duo, 4MB RAM (It's from 2009, don't make fun of me)
Limit: 2^25 = 33554432 
--------------------------------------------------------------------------------
        Basic Algorithm    2wheel(odds only)    23wheel      235wheel
Ruby             16.79s                          4.829s
Python           12.56s                3.88s                   2.248s
Go                1.39s               0.564s                   0.431s
C                 1.30s               0.546s                   0.349s
C(-O3)            1.24s               0.535s                   0.352s         

So for version 2.0 of this test, it shows that it pays to compile your language.
Really it is somewhat unfair, as there is no way that ruby or python could compete
with something that could optimize away some of the loop structures needed for
the wheel classes.

Apparently ruby sucks at doing this kind of number crunching, since it's 23 wheel
can't beat python's odds-only wheel.  Probably too many complications, making it 
too difficult.  It's also really weird, since it's almost a wheel23, but doesn't
let the outermost loop ignore multiples of 3.  Strange in my book.  This was also
my first implementation, so it holds a special place in my heart.

Python's performance is quite a bit better than Ruby's.  It gies about a 33% increse 
in the throughput, and the odds only very beats the 23 wheel of Ruby's.  Comparing 
the basic algorithm with the 235 whee optimization is over a 300% speedup (322.5% or so).
The 235 wheel is also much more compilcated to code, as it requires a lot of special 
attention to very subtle tricks.

So far we have only talked about interpreted languages.  Now we move onto the 
languages that were built for this sort of problem, compiled and optimized.  
We have our algorithms in hand, so we should try one of the more forgiving compiled
languages.  I chose Go.

Coding the entire thing in go went better than I though, although there was some
cross eyes when I was converting between float64, int64, uint64, you get the 
picture.  Go is strongly typed, so these conversions are necesssary for the 
compiler to know what is going on, and allow the compile to decide what a lot
of the variable types are at runtime.  That being said, there were lots of problems
converting the two complex algorithms into Go.  However, the results were spectacular!
We see a 12x performance increase at the basic level, closer to 3x for the odds-only
implementation, and we see around a 5.5x boost in performance on the 235 wheel.  Whoa.

Still talking about Go, there are some things that just can't be beat. The type 
inference is a saver (as we will see when we get to C).  I could probably make this 
even faster by declaring the arrays as static variables (which I will get around to)
and a couple of other things.

C.  This is the one that I wanted to use as a golden standard for the others to be
measured by.  I was incredibly impressed that Go could keep up with (and beat) C
in some cases.  I also learned a valuable lesson in implicit vs explicit volatile
declaration of variables.  The counters that keep track at the end of how many
primes we've found, and the max one, started out as implicitly non-volatile.
This was very bad when I went to try the -O3 optimization, because suddenly I was
reading garbage into my counter value, breaking the project.  By declaring
them as volatile, I saw a performance hit (duh), but I was getting the right numbers.

For now, hands down, the fastest language is C.  But again, I was very impressed
with how Go held up again it.  I might try pushing the compiled languages to higher
limits and checking the speeds, but that could wind up breaking a lot of things as
we get cloesr to the 32bit barrier.

Fun though.
